{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "These are some libraries that will need to be downloaded if the next cell throws some ModuleNotFound errors. Delete the # of the line who is missing and run the cell."
      ],
      "metadata": {
        "id": "N6D-WClNQrYp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c-ITFgdaLZWv"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install pandas\n",
        "!pip install google-cloud-storage"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Library Imports and Back End Setup**\n",
        "Nothing needs to be changed here, this cell just imports all the libraries our code needs to run, and gets Google Drive mounted to this notebook. This is also where our helper functions live so run this for sure!\n",
        "\n",
        "You **will** need to approve this notebook to having access to your local Google Drive, it will be a little pop up when this cell gets run!"
      ],
      "metadata": {
        "id": "1LFgsMqHQ2h7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tempfile\n",
        "import re\n",
        "import pandas as pd\n",
        "from io import FileIO\n",
        "from google.cloud import storage\n",
        "from google.oauth2 import service_account\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive')\n",
        "_client = storage.Client.from_service_account_json(\"/content/gdrive/Shareddrives/LCLLC/fuelcast-storage-credentials.json\")\n",
        "\n",
        "\n",
        "def download_temp(bucket: str, remote_path: str) -> tempfile.NamedTemporaryFile:\n",
        "      \"\"\"[summary]\n",
        "      Download a file from GCS and write it to a temporary file on disk. Return the named\n",
        "      temporary file.\n",
        "      Args:\n",
        "      :param bucket_name: The name of the source bucket\n",
        "      :param remote_path: The source path of the source blob.\n",
        "      :return:\n",
        "      \"\"\"\n",
        "      bucket = _client.bucket(bucket)\n",
        "      blob = bucket.blob(remote_path)\n",
        "\n",
        "      fp = tempfile.NamedTemporaryFile()\n",
        "\n",
        "      _client.download_blob_to_file(blob, fp)\n",
        "      fp.seek(0)\n",
        "      return fp\n",
        "\n",
        "def upload_temp(\n",
        "        bucket_name: str, source_file_obj: FileIO, destination_blob_name: str\n",
        "    ) -> None:\n",
        "        \"\"\"[summary]\n",
        "        Upload a file object from disk. Works with temp files, should also work with \"real\" files as long\n",
        "        as they're open as a file object. TODO test real files\n",
        "        Args:\n",
        "        :param bucket_name: Bucket to upload file to\n",
        "        :param source_file_obj: An active file object to upload\n",
        "        :param destination_blob_name: A name, including any \"subdirectories\", to upload the blob to (but not bucket)\n",
        "        :return:\n",
        "        \"\"\"\n",
        "        bucket = _client.bucket(bucket_name)\n",
        "        blob = bucket.blob(destination_blob_name)\n",
        "\n",
        "        blob.upload_from_file(source_file_obj, rewind=True)\n",
        "        # We return the blob object in order to make the temporary file public for download in main.py\n",
        "        return blob\n",
        "\n",
        "def list_blobs_names(bucket_name: str, p: str = \"\") -> list:\n",
        "    \"\"\"[summary]\n",
        "    Return a list of all blob names in the given bucket matching the optional prefix p\n",
        "    Args:\n",
        "    :param bucket_name: The name of the source bucket\n",
        "    :param p: An optional destination folder path if the sourced files are in a specific folder.\n",
        "    :return:\n",
        "    \"\"\"\n",
        "    blobs = _client.list_blobs(bucket_name, prefix=p)\n",
        "    blobnames = [x.name for x in blobs]\n",
        "    return blobnames"
      ],
      "metadata": {
        "id": "XRTLgdngOF68"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Input** \n",
        "\n",
        "file_name: The name of the file you used when running the GEE script."
      ],
      "metadata": {
        "id": "bxBbitLiQ_5v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "file_name=\"test\""
      ],
      "metadata": {
        "id": "ewn0EI52PeGg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Data Compiler**\n",
        "You don't need to change anything in here, just let the cell run."
      ],
      "metadata": {
        "id": "0efZXxljRLNQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "csvs = list_blobs_names(\"fuelcast-public\",\"Matt/\"+file_name)\n",
        "\n",
        "def num_sort(test_string):\n",
        "    return list(map(int, re.findall(r'\\d+', test_string)))[0]\n",
        "csvs.sort(key=num_sort)\n",
        "\n",
        "csv_list = []\n",
        "for i in csvs:\n",
        "    csv_list.append(pd.read_csv(download_temp(\"fuelcast-public\", i)))\n",
        "result = pd.concat(csv_list)\n",
        "print(result)\n",
        "result.to_csv(\"/content/gdrive/MyDrive/\"+file_name+\".csv\")\n"
      ],
      "metadata": {
        "id": "IiGXpCwZPfZw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}